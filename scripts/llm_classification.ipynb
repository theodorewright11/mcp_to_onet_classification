{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86e3957a",
   "metadata": {},
   "source": [
    "# LLM Classification Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f4db00",
   "metadata": {},
   "source": [
    "## Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2af602a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-detected existing results: mcp_results_2026-02-14.csv\n",
      "\n",
      "Model: gpt-4.1\n",
      "Config: top-80 DWAs -> select up to 15 -> rate up to 125 tasks\n",
      "MCP data:   mcp_data_2026-02-17.csv\n",
      "MCP emb:    voyage_mcp_emb_2026-02-17.npy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()  # reads OPENAI_API_KEY from env\n",
    "\n",
    "# ============================================================\n",
    "# Config — set these before running\n",
    "# ============================================================\n",
    "# These filenames come from the output of data_prep.ipynb.\n",
    "MCP_DATA_FILE = \"mcp_data_2026-02-17.csv\"       # cleaned MCPs to classify (in data/mcp/raw/)\n",
    "MCP_EMB_FILE  = \"voyage_mcp_emb_2026-02-17.npy\" # Voyage embeddings for those MCPs (in data/embeddings/)\n",
    "\n",
    "# Existing results to merge new classifications into.\n",
    "# Set to None to auto-detect the most recent mcp_results_*.csv in data/mcp/results/, or specify explicitly.\n",
    "# Set to \"none\" (string) for a completely fresh run with no merging.\n",
    "EXISTING_RESULTS_FILE = None\n",
    "\n",
    "# LLM / retrieval settings\n",
    "MODEL          = \"gpt-4.1\"\n",
    "TOP_K_DWAS     = 80    # retrieve top 80 DWAs by cosine similarity\n",
    "MAX_DWA_SELECT = 15    # LLM selects up to 15\n",
    "MAX_TASKS      = 125   # max tasks to send to rating prompt\n",
    "TEMPERATURE    = 0.0   # low temp for consistency\n",
    "\n",
    "# ---------- Paths ----------\n",
    "DATA_DIR     = Path(\"../data\")\n",
    "RESULTS_DIR  = DATA_DIR / \"mcp\" / \"results\"\n",
    "RAW_DIR      = DATA_DIR / \"mcp\" / \"raw\"\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ---------- Resolve existing results file ----------\n",
    "if EXISTING_RESULTS_FILE is None:\n",
    "    existing_files = sorted(RESULTS_DIR.glob(\"mcp_results_*.csv\"))\n",
    "    if existing_files:\n",
    "        EXISTING_RESULTS_FILE = existing_files[-1].name\n",
    "        print(f\"Auto-detected existing results: {EXISTING_RESULTS_FILE}\")\n",
    "    else:\n",
    "        EXISTING_RESULTS_FILE = \"none\"\n",
    "        print(\"No existing results found — fresh run.\")\n",
    "elif EXISTING_RESULTS_FILE == \"none\":\n",
    "    print(\"Fresh run — no existing results will be merged.\")\n",
    "else:\n",
    "    print(f\"Using existing results: {EXISTING_RESULTS_FILE}\")\n",
    "\n",
    "# ---------- Derived paths ----------\n",
    "MCP_DATA_PATH  = RAW_DIR / MCP_DATA_FILE\n",
    "MCP_EMB_PATH   = DATA_DIR / \"embeddings\" / MCP_EMB_FILE\n",
    "DWA_EMB_PATH   = DATA_DIR / \"embeddings\" / \"voyage_dwa_emb.npy\"\n",
    "ONET_DATA_PATH = DATA_DIR / \"onet\" / \"onet_data.csv\"\n",
    "\n",
    "print(f\"\\nModel: {MODEL}\")\n",
    "print(f\"Config: top-{TOP_K_DWAS} DWAs -> select up to {MAX_DWA_SELECT} -> rate up to {MAX_TASKS} tasks\")\n",
    "print(f\"MCP data:   {MCP_DATA_FILE}\")\n",
    "print(f\"MCP emb:    {MCP_EMB_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yy8c8rmww5c",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7u33lvx4j0p",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCPs loaded: 1,183\n",
      "O*NET rows loaded: 23,850\n",
      "Unique DWAs: 2,083\n",
      "MCP embeddings: (1183, 1024)\n",
      "DWA embeddings: (2083, 1024)\n",
      "\n",
      "DWA->tasks lookup built: 2,083 DWAs with tasks\n",
      "Avg tasks per DWA: 11.4\n"
     ]
    }
   ],
   "source": [
    "# ---------- Load MCP data ----------\n",
    "mcp_df = pd.read_csv(MCP_DATA_PATH)\n",
    "print(f\"MCPs loaded: {len(mcp_df):,}\")\n",
    "\n",
    "# ---------- Load O*NET data ----------\n",
    "onet_df = pd.read_csv(ONET_DATA_PATH)\n",
    "print(f\"O*NET rows loaded: {len(onet_df):,}\")\n",
    "\n",
    "dwa_titles_unique = onet_df[\"dwa_title\"].dropna().drop_duplicates().reset_index(drop=True).tolist()\n",
    "print(f\"Unique DWAs: {len(dwa_titles_unique):,}\")\n",
    "\n",
    "# ---------- Load embeddings ----------\n",
    "mcp_emb = np.load(MCP_EMB_PATH)\n",
    "dwa_emb = np.load(DWA_EMB_PATH)\n",
    "print(f\"MCP embeddings: {mcp_emb.shape}\")\n",
    "print(f\"DWA embeddings: {dwa_emb.shape}\")\n",
    "\n",
    "assert mcp_emb.shape[0] == len(mcp_df), \"MCP embedding count mismatch\"\n",
    "assert dwa_emb.shape[0] == len(dwa_titles_unique), \"DWA embedding count mismatch\"\n",
    "\n",
    "# ---------- L2 normalize for cosine similarity ----------\n",
    "def l2_normalize(X):\n",
    "    norms = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    norms[norms == 0] = 1\n",
    "    return X / norms\n",
    "\n",
    "mcp_emb_norm = l2_normalize(mcp_emb)\n",
    "dwa_emb_norm = l2_normalize(dwa_emb)\n",
    "\n",
    "# ---------- Build DWA -> tasks lookup ----------\n",
    "dwa_to_tasks = {}\n",
    "for _, row in onet_df.iterrows():\n",
    "    dwa = row[\"dwa_title\"]\n",
    "    if pd.isna(dwa):\n",
    "        continue\n",
    "    if dwa not in dwa_to_tasks:\n",
    "        dwa_to_tasks[dwa] = []\n",
    "    dwa_to_tasks[dwa].append((row[\"task\"], row[\"title\"]))\n",
    "\n",
    "print(f\"\\nDWA->tasks lookup built: {len(dwa_to_tasks):,} DWAs with tasks\")\n",
    "print(f\"Avg tasks per DWA: {np.mean([len(v) for v in dwa_to_tasks.values()]):.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k4eez3f708",
   "metadata": {},
   "source": [
    "# Core Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sr1bw16j1ln",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core functions defined.\n"
     ]
    }
   ],
   "source": [
    "def get_top_dwas(mcp_idx, top_k=TOP_K_DWAS):\n",
    "    \"\"\"Get top-k DWAs by cosine similarity for a given MCP index.\n",
    "    Returns list of (dwa_title, similarity_score) sorted by similarity desc.\"\"\"\n",
    "    mcp_vec = mcp_emb_norm[mcp_idx:mcp_idx+1]  # (1, dim)\n",
    "    sims = (mcp_vec @ dwa_emb_norm.T).flatten()  # (n_dwa,)\n",
    "    top_indices = np.argsort(-sims)[:top_k]\n",
    "    return [(dwa_titles_unique[i], float(sims[i])) for i in top_indices]\n",
    "\n",
    "\n",
    "def get_tasks_for_dwas(selected_dwas_with_sims, max_tasks=MAX_TASKS):\n",
    "    \"\"\"Given selected DWAs (with similarity scores), get tasks underneath them.\n",
    "    Iterates from highest to lowest similarity. If a DWA's new tasks would\n",
    "    push the total over max_tasks, skips that DWA and keeps trying the rest.\n",
    "    This maximizes task coverage while prioritizing the most similar DWAs.\n",
    "    Returns: (tasks_list, used_dwas) where tasks_list is [(task_text, occupation, dwa_title), ...]\n",
    "    and used_dwas is the final list of DWA titles kept.\"\"\"\n",
    "    # Sort by similarity descending\n",
    "    sorted_dwas = sorted(selected_dwas_with_sims, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    tasks_list = []\n",
    "    seen = set()\n",
    "    used_dwas = []\n",
    "    \n",
    "    for dwa_title, sim in sorted_dwas:\n",
    "        # Collect only unseen tasks for this DWA\n",
    "        candidate_tasks = []\n",
    "        for task_text, occ_title in dwa_to_tasks.get(dwa_title, []):\n",
    "            key = (task_text, occ_title)\n",
    "            if key not in seen:\n",
    "                candidate_tasks.append((task_text, occ_title, dwa_title, key))\n",
    "        \n",
    "        # Skip this DWA if its new tasks would exceed the limit\n",
    "        if len(tasks_list) + len(candidate_tasks) > max_tasks:\n",
    "            continue\n",
    "        \n",
    "        # Add all candidate tasks\n",
    "        for task_text, occ_title, dwa_title_inner, key in candidate_tasks:\n",
    "            seen.add(key)\n",
    "            tasks_list.append((task_text, occ_title, dwa_title_inner))\n",
    "        used_dwas.append(dwa_title)\n",
    "    \n",
    "    return tasks_list, used_dwas\n",
    "\n",
    "\n",
    "# ---------- Prompt templates ----------\n",
    "\n",
    "DWA_SELECTION_PROMPT = \"\"\"You are classifying AI agent automation potential for occupational tasks.\n",
    "\n",
    "Below is a description and list of key features and use cases of an AI Model Context Protocol (MCP) server — a plugin-like system that allows AI assistants to access external tools, APIs, or data sources to perform real-world tasks.\n",
    "\n",
    "<mcp_desc>\n",
    "{mcp_desc}\n",
    "</mcp_desc>\n",
    "\n",
    "Below is a list of Detailed Work Activities (DWAs) from the O*NET occupational database. These were retrieved via semantic cosine similarity and may or may not be relevant to this MCP.\n",
    "\n",
    "<dwas>\n",
    "{dwas}\n",
    "</dwas>\n",
    "\n",
    "<question>\n",
    "Which of these DWAs are most likely to contain specific occupational tasks underneath them in the O*NET hierarchy that this MCP could automate or substantially support in real-world deployments?\n",
    "</question>\n",
    "\n",
    "Follow these guidelines when answering:\n",
    "- This is a funnel. Select DWAs whose underlying occupational tasks are most likely automatable or substantially supported by this MCP. Err slightly toward inclusion, but only where the connection is direct and concrete.\n",
    "- Evaluate MCP capabilities strictly based on what is explicitly described or directly implied. Treat connected tools as part of the MCP only if their functionality is directly accessible through the MCP's exposed app or API. You may use general background knowledge to understand technologies and terminology, but do not infer undocumented capabilities, hypothetical future integrations, or functionality beyond what is described.\n",
    "- Interpret DWAs based on their action verbs and the real-world human work they represent in formal occupational contexts, and consider who would own, operate, and be responsible for the workflows of the DWAs. Use background knowledge to understand DWA meaning, but classify only where there is a concrete, direct connection between the MCP's described functionality and the actual workplace tasks implied by the DWA.\n",
    "- Select up to 15 DWAs. If none are relevant, answer \"None.\"\n",
    "- If the MCP description is too vague to determine real capabilities, answer \"Not enough information.\"\n",
    "- If the MCP does not enable a concrete paid occupational activity represented in O*NET, answer \"Not occupationally relevant.\"\n",
    "- Do not treat the fact that something is an MCP server or tool as evidence of relevance — evaluate only the described functionality.\n",
    "\n",
    "Answer with only ONE of the following formats and nothing else:\n",
    "\n",
    "<answer>\n",
    "The numbers of up to 15 selected DWAs from the list above, separated by semicolons (e.g., 1; 5; 12).\n",
    "</answer>\n",
    "\n",
    "Or:\n",
    "\n",
    "<answer>\n",
    "None\n",
    "</answer>\n",
    "\n",
    "Or:\n",
    "\n",
    "<answer>\n",
    "Not enough information\n",
    "</answer>\n",
    "\n",
    "Or:\n",
    "\n",
    "<answer>\n",
    "Not occupationally relevant\n",
    "</answer>\n",
    "\n",
    "Follow these guidelines for your output:\n",
    "- Wrap your final response in <answer> tags.\n",
    "- Do not include DWA text, or any other words/explanation for any of your answers.\"\"\"\n",
    "\n",
    "\n",
    "TASK_RATING_PROMPT = \"\"\"You are classifying AI agent automation potential for occupational tasks.\n",
    "\n",
    "Below is a description and list of key features and use cases of an AI Model Context Protocol (MCP) server — a plugin-like system that allows AI assistants to access external tools, APIs, or data sources to perform real-world tasks.\n",
    "\n",
    "<mcp_desc>\n",
    "{mcp_desc}\n",
    "</mcp_desc>\n",
    "\n",
    "Below is a list of occupational tasks from the O*NET database. Each task is performed by workers in the occupation noted in parentheses. These tasks fall under work activities that were previously identified as potentially automatable by this MCP.\n",
    "\n",
    "<tasks>\n",
    "{tasks_with_occupations}\n",
    "</tasks>\n",
    "\n",
    "<question>\n",
    "For each task, rate on a scale of 1-5 how much this MCP could automate the task in a real-world deployment.\n",
    "</question>\n",
    "\n",
    "Follow these scale description when answering:\n",
    "1 — No meaningful automation (0–10%).\n",
    "The MCP does not meaningfully address this task. Any connection is superficial or incidental.\n",
    "2 — Minimal support (10–30%).\n",
    "The MCP may assist with a small component of the task, but humans still perform nearly all core work.\n",
    "3 — Partial automation (30–60%).\n",
    "The MCP can automate or significantly accelerate a meaningful portion of the core workflow. Human judgment and intervention remain essential.\n",
    "4 — Substantial automation (60–90%).\n",
    "The MCP can perform most of the core task workflow with limited human oversight. A human may initiate, monitor, or handle exceptions.\n",
    "5 — Near-full automation (90–100%).\n",
    "The MCP can execute the task end-to-end in typical scenarios, with little to no human involvement beyond initial setup or oversight.\n",
    "\n",
    "Follow these guidelines:\n",
    "- Rate each task independently based on the MCP's described capabilities.\n",
    "- Each rating should only be a 1, 2, 3, 4, or 5\n",
    "- Provide exactly one rating per task, in the same order as listed.\n",
    "- Evaluate MCP capabilities strictly based on what is explicitly described or directly implied. Treat connected tools as part of the MCP only if their functionality is directly accessible through the MCP's exposed app or API. You may use general background knowledge to understand technologies and terminology, but do not infer undocumented capabilities, hypothetical future integrations, or functionality beyond what is described.\n",
    "- Consider the task as it would be performed in the occupation noted — context matters. The same task description may be more or less automatable depending on the occupational context.\n",
    "- Interpret tasks based on their action verbs and the real-world human work they represent in formal occupational contexts, and consider who would own, operate, and be responsible for the workflows of the task. Use background knowledge to understand task meaning, but classify based on the concrete, direct connection between the MCP's described functionality and the actual workplace tasks.\n",
    "- A rating of 1 is expected and appropriate for tasks that passed the DWA filter but are not actually automatable by this specific MCP. Do not hesitate to use it.\n",
    "\n",
    "\n",
    "Answer ONLY in the following format and nothing else:\n",
    "\n",
    "<ratings>\n",
    "1:[rating]; 2:[rating]; 3:[rating]; ...; N:[rating]\n",
    "</ratings>\n",
    "\n",
    "Follow these guidelines for your output:\n",
    "- Wrap your final response in <ratings> tags.\n",
    "- Provide a semicolon-separated list for ALL tasks provided above.\n",
    "- Use the format: TaskNumber:Rating, where TaskNumber and Rating are each a single integer corresponding to (respectively) the task number of the task provided above list and the automation rating selected for it.\n",
    "- Do not include the task text, or any other words/explanation.\"\"\"\n",
    "\n",
    "\n",
    "def format_dwa_list(dwas_with_sims):\n",
    "    \"\"\"Format numbered DWA list for the prompt.\"\"\"\n",
    "    lines = []\n",
    "    for i, (dwa_title, sim) in enumerate(dwas_with_sims, 1):\n",
    "        lines.append(f\"{i}. {dwa_title}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def format_task_list(tasks):\n",
    "    \"\"\"Format numbered task list for the prompt. tasks: [(task_text, occupation, dwa_title), ...]\"\"\"\n",
    "    lines = []\n",
    "    for i, (task_text, occ, dwa) in enumerate(tasks, 1):\n",
    "        lines.append(f\"{i}. {task_text} ({occ})\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def call_llm(prompt, max_retries=3):\n",
    "    \"\"\"Call GPT-4.1 with retry logic. Returns raw response text.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=TEMPERATURE,\n",
    "                max_tokens=4096,\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"  API error (attempt {attempt+1}/{max_retries}): {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(5 * (attempt + 1))\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "\n",
    "def parse_dwa_response(response_text, dwas_with_sims):\n",
    "    \"\"\"Parse DWA selection response. Returns (selected_dwa_titles, status) where\n",
    "    status is 'selected', 'none', 'not_enough_info', or 'not_occ_relevant'.\"\"\"\n",
    "    # Extract content between <answer> tags\n",
    "    match = re.search(r\"<answer>\\s*(.*?)\\s*</answer>\", response_text, re.DOTALL)\n",
    "    if not match:\n",
    "        return [], \"parse_error\"\n",
    "    \n",
    "    content = match.group(1).strip()\n",
    "    \n",
    "    if content.lower() == \"none\":\n",
    "        return [], \"none\"\n",
    "    if \"not enough information\" in content.lower():\n",
    "        return [], \"not_enough_info\"\n",
    "    if \"not occupationally relevant\" in content.lower():\n",
    "        return [], \"not_occ_relevant\"\n",
    "    \n",
    "    # Parse semicolon-separated numbers\n",
    "    try:\n",
    "        numbers = [int(n.strip()) for n in content.split(\";\") if n.strip()]\n",
    "    except ValueError:\n",
    "        return [], \"parse_error\"\n",
    "    \n",
    "    # Map numbers to DWA titles (1-indexed)\n",
    "    selected = []\n",
    "    for num in numbers:\n",
    "        if 1 <= num <= len(dwas_with_sims):\n",
    "            selected.append(dwas_with_sims[num - 1])  # (title, sim)\n",
    "    \n",
    "    return selected, \"selected\"\n",
    "\n",
    "\n",
    "def parse_task_ratings(response_text, tasks):\n",
    "    \"\"\"Parse task rating response. Returns list of (task_text, occupation, dwa_title, rating).\"\"\"\n",
    "    match = re.search(r\"<ratings>\\s*(.*?)\\s*</ratings>\", response_text, re.DOTALL)\n",
    "    if not match:\n",
    "        return []\n",
    "    \n",
    "    content = match.group(1).strip()\n",
    "    ratings = []\n",
    "    \n",
    "    for pair in content.split(\";\"):\n",
    "        pair = pair.strip()\n",
    "        if not pair:\n",
    "            continue\n",
    "        try:\n",
    "            num_str, rating_str = pair.split(\":\")\n",
    "            num = int(num_str.strip())\n",
    "            rating = int(rating_str.strip())\n",
    "            if 1 <= num <= len(tasks) and 1 <= rating <= 5:\n",
    "                task_text, occ, dwa = tasks[num - 1]\n",
    "                ratings.append((task_text, occ, dwa, rating))\n",
    "        except (ValueError, IndexError):\n",
    "            continue\n",
    "    \n",
    "    return ratings\n",
    "\n",
    "\n",
    "print(\"Core functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2lacxl55yxo",
   "metadata": {},
   "source": [
    "# Select MCPs to Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbhiilcxutj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCPs to classify: 1183\n",
      "MCPs to process this session: 1183\n",
      "Output path: ..\\data\\mcp\\results\\mcp_results_2026-02-18.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Select MCPs to classify\n",
    "# By default, all MCPs in mcp_df are classified (they are the\n",
    "# new MCPs not yet in the existing results).\n",
    "# ============================================================\n",
    "run_indices = list(range(len(mcp_df)))\n",
    "print(f\"MCPs to classify: {len(run_indices)}\")\n",
    "\n",
    "# ---------- Output path for this run's results ----------\n",
    "date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "OUTPUT_PATH = RESULTS_DIR / f\"mcp_results_{date_str}.csv\"\n",
    "\n",
    "# Resume logic: if a partial output already exists for today's run,\n",
    "# skip the MCPs that were already processed.\n",
    "if OUTPUT_PATH.exists():\n",
    "    partial_df = pd.read_csv(OUTPUT_PATH)\n",
    "    already_done_urls = set(partial_df[\"url\"].dropna().tolist())\n",
    "    before = len(run_indices)\n",
    "    run_indices = [i for i in run_indices if mcp_df.loc[i, \"url\"] not in already_done_urls]\n",
    "    print(f\"Resuming: skipping {before - len(run_indices)} already-processed MCPs\")\n",
    "else:\n",
    "    partial_df = pd.DataFrame()\n",
    "\n",
    "print(f\"MCPs to process this session: {len(run_indices)}\")\n",
    "print(f\"Output path: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kh6jqw71hrl",
   "metadata": {},
   "source": [
    "# Run Classification Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bms3cwe727q",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/5] Amadeus MCP Server\n",
      "  Top 80 DWAs retrieved (sim range: 0.4317 - 0.3385)\n",
      "  DWA selection: selected (7 DWAs)\n",
      "  Tasks retrieved: 80 (from 7/7 DWAs)\n",
      "  Tasks rated: 80/80\n",
      "\n",
      "[2/5] SumoLogic MCP Server\n",
      "  Top 80 DWAs retrieved (sim range: 0.5076 - 0.3518)\n",
      "  DWA selection: selected (15 DWAs)\n",
      "  Tasks retrieved: 125 (from 12/15 DWAs)\n",
      "  Tasks rated: 125/125\n",
      "\n",
      "[3/5] iRacing\n",
      "  Top 80 DWAs retrieved (sim range: 0.4526 - 0.3386)\n",
      "  DWA selection: selected (15 DWAs)\n",
      "  Tasks retrieved: 122 (from 11/15 DWAs)\n",
      "  Tasks rated: 122/122\n",
      "\n",
      "[4/5] DiceDB MCP\n",
      "  Top 80 DWAs retrieved (sim range: 0.4192 - 0.3119)\n",
      "  DWA selection: selected (15 DWAs)\n",
      "  Tasks retrieved: 123 (from 10/15 DWAs)\n",
      "  Tasks rated: 123/123\n",
      "\n",
      "[5/5] Amadeus MCP Server\n",
      "  Top 80 DWAs retrieved (sim range: 0.4058 - 0.3208)\n",
      "  DWA selection: selected (15 DWAs)\n",
      "  Tasks retrieved: 124 (from 11/15 DWAs)\n",
      "  Tasks rated: 124/124\n",
      "\n",
      "============================================================\n",
      "Classification complete. 5 MCPs processed.\n",
      "Results saved to: ..\\data\\mcp\\gpt-4.1_dwa_task_classification_2026-02-13_3.csv\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for progress_i, mcp_idx in enumerate(run_indices):\n",
    "    row = mcp_df.iloc[mcp_idx]\n",
    "    title = row[\"title\"]\n",
    "    url = row[\"url\"]\n",
    "    mcp_desc = row[\"text_for_llm\"]\n",
    "    \n",
    "    print(f\"\\n[{progress_i+1}/{len(run_indices)}] {title}\")\n",
    "    \n",
    "    # --- Step 1: Get top DWAs by cosine similarity ---\n",
    "    top_dwas = get_top_dwas(mcp_idx)\n",
    "    print(f\"  Top {len(top_dwas)} DWAs retrieved (sim range: {top_dwas[0][1]:.4f} - {top_dwas[-1][1]:.4f})\")\n",
    "    \n",
    "    # --- Step 2: DWA selection prompt ---\n",
    "    dwa_prompt = DWA_SELECTION_PROMPT.format(\n",
    "        mcp_desc=mcp_desc,\n",
    "        dwas=format_dwa_list(top_dwas)\n",
    "    )\n",
    "    \n",
    "    dwa_response_raw = call_llm(dwa_prompt)\n",
    "    selected_dwas, dwa_status = parse_dwa_response(dwa_response_raw, top_dwas)\n",
    "    \n",
    "    print(f\"  DWA selection: {dwa_status} ({len(selected_dwas)} DWAs)\")\n",
    "    \n",
    "    # Build result dict with all MCP data\n",
    "    result = {\n",
    "        \"title\": title,\n",
    "        \"url\": url,\n",
    "        \"text_for_llm\": mcp_desc,\n",
    "        \"uploaded_clean\": row.get(\"uploaded_clean\", \"\"),\n",
    "        \"dwa_status\": dwa_status,\n",
    "        \"dwas_selected\": \"; \".join([d[0] for d in selected_dwas]) if selected_dwas else \"\",\n",
    "        \"n_dwas_selected\": len(selected_dwas),\n",
    "        \"dwa_response_raw\": dwa_response_raw,\n",
    "        \"task_ratings\": \"\",\n",
    "        \"task_rating_response_raw\": \"\",\n",
    "        \"n_tasks_rated\": 0,\n",
    "    }\n",
    "    \n",
    "    # --- Step 3: If DWAs were selected, get tasks and rate them ---\n",
    "    if dwa_status == \"selected\" and len(selected_dwas) > 0:\n",
    "        tasks, used_dwas = get_tasks_for_dwas(selected_dwas, max_tasks=MAX_TASKS)\n",
    "        print(f\"  Tasks retrieved: {len(tasks)} (from {len(used_dwas)}/{len(selected_dwas)} DWAs)\")\n",
    "        \n",
    "        if len(tasks) > 0:\n",
    "            task_prompt = TASK_RATING_PROMPT.format(\n",
    "                mcp_desc=mcp_desc,\n",
    "                tasks_with_occupations=format_task_list(tasks)\n",
    "            )\n",
    "            \n",
    "            task_response_raw = call_llm(task_prompt)\n",
    "            rated_tasks = parse_task_ratings(task_response_raw, tasks)\n",
    "            \n",
    "            print(f\"  Tasks rated: {len(rated_tasks)}/{len(tasks)}\")\n",
    "            \n",
    "            # Format task ratings as \"task_text (occupation): rating\" separated by semicolons\n",
    "            task_ratings_str = \"; \".join(\n",
    "                [f\"{t} ({o}): {r}\" for t, o, d, r in rated_tasks]\n",
    "            )\n",
    "            \n",
    "            result[\"task_ratings\"] = task_ratings_str\n",
    "            result[\"task_rating_response_raw\"] = task_response_raw\n",
    "            result[\"n_tasks_rated\"] = len(rated_tasks)\n",
    "            result[\"n_tasks_sent\"] = len(tasks)\n",
    "            result[\"dwas_used_for_tasks\"] = \"; \".join(used_dwas)\n",
    "    \n",
    "    results.append(result)\n",
    "    \n",
    "    # --- Incremental save ---\n",
    "    new_results_df = pd.DataFrame(results)\n",
    "    if not existing_df.empty:\n",
    "        save_df = pd.concat([existing_df, new_results_df], ignore_index=True)\n",
    "    else:\n",
    "        save_df = new_results_df\n",
    "    save_df.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Classification complete. {len(results)} MCPs processed.\")\n",
    "print(f\"Results saved to: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7p1to85jo3u",
   "metadata": {},
   "source": [
    "# Task-Level Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xnlzwkld1r8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Merge new results with historical results + run task aggregation\n",
    "# ============================================================\n",
    "\n",
    "# Load this run's results\n",
    "new_results_df = pd.read_csv(OUTPUT_PATH)\n",
    "print(f\"New MCPs classified this run: {len(new_results_df)}\")\n",
    "\n",
    "# Merge with historical results from previous runs\n",
    "if EXISTING_RESULTS_FILE != \"none\":\n",
    "    historical_df = pd.read_csv(RESULTS_DIR / EXISTING_RESULTS_FILE)\n",
    "    print(f\"Historical results: {len(historical_df)} MCPs\")\n",
    "    results_df = pd.concat([historical_df, new_results_df], ignore_index=True)\n",
    "else:\n",
    "    results_df = new_results_df\n",
    "\n",
    "# Save combined results\n",
    "results_df.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"Combined results saved: {len(results_df)} MCPs -> {OUTPUT_PATH.name}\")\n",
    "\n",
    "# ============================================================\n",
    "# Build task-level aggregation (over all MCPs in combined results)\n",
    "# ============================================================\n",
    "all_task_ratings = []\n",
    "\n",
    "for _, row in results_df.iterrows():\n",
    "    ratings_str = row.get(\"task_ratings\", \"\")\n",
    "    if not isinstance(ratings_str, str) or not ratings_str.strip():\n",
    "        continue\n",
    "\n",
    "    mcp_title = row[\"title\"]\n",
    "    mcp_url = row[\"url\"]\n",
    "\n",
    "    for entry in ratings_str.split(\"; \"):\n",
    "        entry = entry.strip()\n",
    "        if not entry:\n",
    "            continue\n",
    "        match = re.match(r\"^(.+):\\s*(\\d)$\", entry)\n",
    "        if not match:\n",
    "            continue\n",
    "        task_occ_str = match.group(1).strip()\n",
    "        rating = int(match.group(2))\n",
    "\n",
    "        occ_match = re.match(r\"^(.+)\\s*\\(([^)]+)\\)$\", task_occ_str)\n",
    "        if occ_match:\n",
    "            task_text = occ_match.group(1).strip()\n",
    "            occupation = occ_match.group(2).strip()\n",
    "        else:\n",
    "            task_text = task_occ_str\n",
    "            occupation = \"\"\n",
    "\n",
    "        all_task_ratings.append({\n",
    "            \"task\": task_text,\n",
    "            \"occupation\": occupation,\n",
    "            \"rating\": rating,\n",
    "            \"mcp_title\": mcp_title,\n",
    "            \"mcp_url\": mcp_url,\n",
    "        })\n",
    "\n",
    "task_ratings_flat = pd.DataFrame(all_task_ratings)\n",
    "print(f\"\\nTotal task-rating pairs: {len(task_ratings_flat):,}\")\n",
    "print(f\"Unique (task, occupation) pairs: {task_ratings_flat.groupby(['task', 'occupation']).ngroups:,}\")\n",
    "\n",
    "task_agg = task_ratings_flat.groupby([\"task\", \"occupation\"]).agg(\n",
    "    n_ratings=(\"rating\", \"count\"),\n",
    "    mean_rating=(\"rating\", \"mean\"),\n",
    "    median_rating=(\"rating\", \"median\"),\n",
    "    max_rating=(\"rating\", \"max\"),\n",
    "    min_rating=(\"rating\", \"min\"),\n",
    "    p25_rating=(\"rating\", lambda x: np.percentile(x, 25)),\n",
    "    p75_rating=(\"rating\", lambda x: np.percentile(x, 75)),\n",
    ").reset_index()\n",
    "\n",
    "for col in [\"mean_rating\", \"median_rating\", \"p25_rating\", \"p75_rating\"]:\n",
    "    task_agg[col] = task_agg[col].round(2)\n",
    "\n",
    "task_agg = task_agg.sort_values([\"n_ratings\", \"mean_rating\"], ascending=[False, False]).reset_index(drop=True)\n",
    "\n",
    "TASK_AGG_PATH = RESULTS_DIR / f\"task_results_{date_str}.csv\"\n",
    "task_agg.to_csv(TASK_AGG_PATH, index=False)\n",
    "\n",
    "print(f\"\\nTask aggregation saved: {TASK_AGG_PATH.name}  ({len(task_agg):,} rows)\")\n",
    "task_agg.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6vaw8dr6e",
   "metadata": {},
   "source": [
    "# Batch API Classification Pipeline\n",
    "\n",
    "Uses OpenAI's Batch API (50% cheaper, higher rate limits, up to 24h turnaround). Requires **two sequential batches** because task rating prompts depend on DWA selection results.\n",
    "\n",
    "**How to use — run cells in this order:**\n",
    "\n",
    "1. Run the prerequisite cells above: \"Imports and Config\", \"Load Data\", \"Core Functions\", \"Select MCPs to Classify\"\n",
    "2. Run \"Batch Config + Output Paths\"\n",
    "3. Run \"Generate DWA Selection JSONL\" → then \"Upload + Create Batch\"\n",
    "4. Run the **DWA poll cell** — it auto-waits (polls every 30s) until done, then downloads results\n",
    "5. Run \"Parse DWA Results\" — parses responses + saves intermediate state to disk\n",
    "6. Run \"Generate Task Rating JSONL\" → then \"Upload + Create Task Batch\"\n",
    "7. Run the **Task poll cell** — same auto-wait behavior\n",
    "8. Run \"Parse + Combine + Save\" — produces the final CSV (same format as synchronous pipeline)\n",
    "9. Run \"Task-Level Aggregation\" if you want the aggregated stats\n",
    "\n",
    "**Kernel restart safe:** Intermediate state (`batch_mcp_meta`, `task_batch_meta`) is saved to `.pkl` files in `data/batch/`. If you restart the kernel, just re-run the prerequisite cells, set the `DWA_BATCH_ID` / `TASK_BATCH_ID` variable manually, and continue from the poll cell.\n",
    "\n",
    "**Prerequisite cells:** Imports and Config, Load Data, Core Functions, Select MCPs to Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9tn593xv9dm",
   "metadata": {},
   "source": [
    "## Batch Config + Output Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "qva3fqtbntn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch output: ..\\data\\mcp\\results\\mcp_results_2026-02-18.csv\n",
      "MCPs to process via batch: 1183\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ---------- Batch output paths ----------\n",
    "BATCH_DIR = DATA_DIR / \"batch\"\n",
    "BATCH_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "BATCH_OUTPUT_PATH = RESULTS_DIR / f\"mcp_results_{date_str}.csv\"\n",
    "\n",
    "# JSONL files for the two batches\n",
    "DWA_JSONL_PATH  = BATCH_DIR / f\"dwa_selection_batch_{date_str}.jsonl\"\n",
    "TASK_JSONL_PATH = BATCH_DIR / f\"task_rating_batch_{date_str}.jsonl\"\n",
    "\n",
    "# Resume logic for batch: if a partial output exists for today's run,\n",
    "# skip already-classified MCPs (excluding api_error rows so they get retried).\n",
    "if BATCH_OUTPUT_PATH.exists():\n",
    "    existing_batch_df = pd.read_csv(BATCH_OUTPUT_PATH)\n",
    "    total_existing = len(existing_batch_df)\n",
    "    existing_batch_df = existing_batch_df[existing_batch_df[\"dwa_status\"] != \"api_error\"]\n",
    "    n_dropped = total_existing - len(existing_batch_df)\n",
    "    if n_dropped > 0:\n",
    "        print(f\"Dropped {n_dropped} api_error rows (will re-process)\")\n",
    "    already_done_batch_urls = set(existing_batch_df[\"url\"].dropna().tolist())\n",
    "    batch_run_indices = [i for i in run_indices if mcp_df.loc[i, \"url\"] not in already_done_batch_urls]\n",
    "    print(f\"Resuming: skipping {len(run_indices) - len(batch_run_indices)} already-classified MCPs\")\n",
    "else:\n",
    "    existing_batch_df = pd.DataFrame()\n",
    "    batch_run_indices = list(run_indices)\n",
    "\n",
    "print(f\"Batch output: {BATCH_OUTPUT_PATH}\")\n",
    "print(f\"MCPs to process via batch: {len(batch_run_indices)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r9v4fvz655",
   "metadata": {},
   "source": [
    "## Batch 1: Generate DWA Selection JSONL + Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6hbmr90v3pd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWA selection JSONL written: ..\\data\\batch\\dwa_selection_batch_2026-02-18.jsonl\n",
      "Requests: 1183\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Build DWA selection JSONL + precompute top DWAs per MCP\n",
    "# ============================================================\n",
    "\n",
    "# Store per-MCP metadata needed for later steps\n",
    "batch_mcp_meta = {}  # custom_id -> {mcp_idx, title, url, text_for_llm, uploaded_clean, top_dwas}\n",
    "\n",
    "with open(DWA_JSONL_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    for mcp_idx in batch_run_indices:\n",
    "        row = mcp_df.iloc[mcp_idx]\n",
    "        custom_id = f\"dwa-{mcp_idx}\"\n",
    "        \n",
    "        # Get top DWAs by cosine similarity\n",
    "        top_dwas = get_top_dwas(mcp_idx)\n",
    "        \n",
    "        # Build the prompt (same as synchronous pipeline)\n",
    "        dwa_prompt = DWA_SELECTION_PROMPT.format(\n",
    "            mcp_desc=row[\"text_for_llm\"],\n",
    "            dwas=format_dwa_list(top_dwas)\n",
    "        )\n",
    "        \n",
    "        # Write JSONL line\n",
    "        batch_line = {\n",
    "            \"custom_id\": custom_id,\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": MODEL,\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": dwa_prompt}],\n",
    "                \"temperature\": TEMPERATURE,\n",
    "                \"max_tokens\": 4096,\n",
    "            }\n",
    "        }\n",
    "        f.write(json.dumps(batch_line) + \"\\n\")\n",
    "        \n",
    "        # Save metadata\n",
    "        batch_mcp_meta[custom_id] = {\n",
    "            \"mcp_idx\": mcp_idx,\n",
    "            \"title\": row[\"title\"],\n",
    "            \"url\": row[\"url\"],\n",
    "            \"text_for_llm\": row[\"text_for_llm\"],\n",
    "            \"uploaded_clean\": row.get(\"uploaded_clean\", \"\"),\n",
    "            \"top_dwas\": top_dwas,\n",
    "        }\n",
    "\n",
    "print(f\"DWA selection JSONL written: {DWA_JSONL_PATH}\")\n",
    "print(f\"Requests: {len(batch_mcp_meta)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mlkze5phwia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file: file-MZiLdckErAkvDWrt7JeMdj\n",
      "Batch created: batch_69960a0aeb88819084985f8c8a1447b5\n",
      "Status: validating\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Upload JSONL + create batch\n",
    "# ============================================================\n",
    "\n",
    "# Upload the file\n",
    "dwa_batch_file = client.files.create(\n",
    "    file=open(DWA_JSONL_PATH, \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "print(f\"Uploaded file: {dwa_batch_file.id}\")\n",
    "\n",
    "# Create the batch\n",
    "dwa_batch = client.batches.create(\n",
    "    input_file_id=dwa_batch_file.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\"description\": f\"DWA selection for {len(batch_mcp_meta)} MCPs\"}\n",
    ")\n",
    "print(f\"Batch created: {dwa_batch.id}\")\n",
    "print(f\"Status: {dwa_batch.status}\")\n",
    "\n",
    "# Save batch ID for retrieval\n",
    "DWA_BATCH_ID = dwa_batch.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdx7czmlh5",
   "metadata": {},
   "source": [
    "## Batch 1: Poll Status + Retrieve DWA Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74xba6edjdt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:50:54] Status: validating | 0/0 completed, 0 failed\n",
      "[11:51:24] Status: validating | 0/0 completed, 0 failed\n",
      "[11:51:55] Status: in_progress | 0/1183 completed, 0 failed\n",
      "[11:52:25] Status: in_progress | 0/1183 completed, 0 failed\n",
      "[11:52:55] Status: in_progress | 74/1183 completed, 0 failed\n",
      "[11:53:25] Status: in_progress | 677/1183 completed, 0 failed\n",
      "[11:53:55] Status: in_progress | 1153/1183 completed, 0 failed\n",
      "[11:54:26] Status: finalizing | 1183/1183 completed, 0 failed\n",
      "[11:54:56] Status: completed | 1183/1183 completed, 0 failed\n",
      "\n",
      "DWA batch complete! Downloaded 1183 results.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Poll DWA batch until complete (auto-waits, checks every 30s)\n",
    "# If you restarted the kernel, set DWA_BATCH_ID manually first:\n",
    "#   DWA_BATCH_ID = \"batch_...\"\n",
    "# ============================================================\n",
    "\n",
    "import pickle\n",
    "\n",
    "POLL_INTERVAL = 30  # seconds between status checks\n",
    "\n",
    "while True:\n",
    "    dwa_batch_status = client.batches.retrieve(DWA_BATCH_ID)\n",
    "    status = dwa_batch_status.status\n",
    "    counts = dwa_batch_status.request_counts\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] Status: {status} | \"\n",
    "          f\"{counts.completed}/{counts.total} completed, {counts.failed} failed\")\n",
    "    \n",
    "    if status == \"completed\":\n",
    "        # Download output\n",
    "        dwa_output_content = client.files.content(dwa_batch_status.output_file_id).text\n",
    "        dwa_output_lines = [json.loads(line) for line in dwa_output_content.strip().split(\"\\n\")]\n",
    "        print(f\"\\nDWA batch complete! Downloaded {len(dwa_output_lines)} results.\")\n",
    "        \n",
    "        if dwa_batch_status.error_file_id:\n",
    "            dwa_error_content = client.files.content(dwa_batch_status.error_file_id).text\n",
    "            print(f\"Error file:\\n{dwa_error_content[:2000]}\")\n",
    "        break\n",
    "    \n",
    "    elif status in (\"failed\", \"expired\", \"cancelled\"):\n",
    "        print(f\"\\nBatch {status}!\")\n",
    "        if dwa_batch_status.errors:\n",
    "            for err in dwa_batch_status.errors.data:\n",
    "                print(f\"  {err.code}: {err.message}\")\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        time.sleep(POLL_INTERVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "l8u8vjj0rlp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful DWA responses: 1183/1183\n",
      "\n",
      "DWA parsing summary:\n",
      "  selected: 1182\n",
      "  not_enough_info: 1\n",
      "\n",
      "Intermediate state saved to: ..\\data\\batch\\batch_mcp_meta_2026-02-18.pkl\n",
      "(If you restart the kernel before Batch 2, this will be reloaded automatically)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Parse DWA batch results + save intermediate state to disk\n",
    "# ============================================================\n",
    "\n",
    "# Map custom_id -> response text\n",
    "dwa_responses = {}\n",
    "for line in dwa_output_lines:\n",
    "    custom_id = line[\"custom_id\"]\n",
    "    if line.get(\"error\"):\n",
    "        print(f\"  Error for {custom_id}: {line['error']}\")\n",
    "        continue\n",
    "    response_body = line[\"response\"][\"body\"]\n",
    "    dwa_responses[custom_id] = response_body[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "print(f\"Successful DWA responses: {len(dwa_responses)}/{len(dwa_output_lines)}\")\n",
    "\n",
    "# Parse each response using existing parse_dwa_response function\n",
    "dwa_parse_summary = {\"selected\": 0, \"none\": 0, \"not_enough_info\": 0, \"not_occ_relevant\": 0, \"parse_error\": 0, \"api_error\": 0}\n",
    "\n",
    "for custom_id, meta in batch_mcp_meta.items():\n",
    "    if custom_id not in dwa_responses:\n",
    "        meta[\"dwa_status\"] = \"api_error\"\n",
    "        meta[\"selected_dwas\"] = []\n",
    "        meta[\"dwa_response_raw\"] = \"\"\n",
    "        dwa_parse_summary[\"api_error\"] += 1\n",
    "        continue\n",
    "    \n",
    "    response_text = dwa_responses[custom_id]\n",
    "    selected_dwas, dwa_status = parse_dwa_response(response_text, meta[\"top_dwas\"])\n",
    "    \n",
    "    meta[\"dwa_status\"] = dwa_status\n",
    "    meta[\"selected_dwas\"] = selected_dwas\n",
    "    meta[\"dwa_response_raw\"] = response_text\n",
    "    dwa_parse_summary[dwa_status] = dwa_parse_summary.get(dwa_status, 0) + 1\n",
    "\n",
    "print(f\"\\nDWA parsing summary:\")\n",
    "for status, count in sorted(dwa_parse_summary.items(), key=lambda x: -x[1]):\n",
    "    if count > 0:\n",
    "        print(f\"  {status}: {count}\")\n",
    "\n",
    "# Save intermediate state so Batch 2 survives a kernel restart\n",
    "BATCH_META_PATH = BATCH_DIR / f\"batch_mcp_meta_{date_str}.pkl\"\n",
    "with open(BATCH_META_PATH, \"wb\") as f:\n",
    "    pickle.dump(batch_mcp_meta, f)\n",
    "print(f\"\\nIntermediate state saved to: {BATCH_META_PATH}\")\n",
    "print(\"(If you restart the kernel before Batch 2, this will be reloaded automatically)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeofojoumsp",
   "metadata": {},
   "source": [
    "## Batch 2: Generate Task Rating JSONL + Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aisimmvjzi6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task rating JSONL written: ..\\data\\batch\\task_rating_batch_2026-02-18.jsonl\n",
      "Requests: 1182 (skipped 1 MCPs with no selected DWAs/tasks)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Build task rating JSONL for MCPs that had DWAs selected\n",
    "# If kernel was restarted, reloads batch_mcp_meta from disk.\n",
    "# ============================================================\n",
    "import pickle\n",
    "\n",
    "BATCH_META_PATH = BATCH_DIR / f\"batch_mcp_meta_{date_str}.pkl\"\n",
    "\n",
    "# Reload intermediate state if not in memory (kernel restart)\n",
    "if \"batch_mcp_meta\" not in dir() or not batch_mcp_meta:\n",
    "    if BATCH_META_PATH.exists():\n",
    "        with open(BATCH_META_PATH, \"rb\") as f:\n",
    "            batch_mcp_meta = pickle.load(f)\n",
    "        print(f\"Reloaded batch_mcp_meta from disk ({len(batch_mcp_meta)} MCPs)\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"No saved state found at {BATCH_META_PATH}. \"\n",
    "                                \"Run Batch 1 cells first.\")\n",
    "\n",
    "task_batch_meta = {}  # custom_id -> {tasks, used_dwas, dwa_custom_id}\n",
    "n_skipped = 0\n",
    "\n",
    "with open(TASK_JSONL_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    for dwa_custom_id, meta in batch_mcp_meta.items():\n",
    "        if meta[\"dwa_status\"] != \"selected\" or len(meta[\"selected_dwas\"]) == 0:\n",
    "            n_skipped += 1\n",
    "            continue\n",
    "        \n",
    "        mcp_idx = meta[\"mcp_idx\"]\n",
    "        task_custom_id = f\"task-{mcp_idx}\"\n",
    "        \n",
    "        # Get tasks for selected DWAs (same logic as synchronous pipeline)\n",
    "        tasks, used_dwas = get_tasks_for_dwas(meta[\"selected_dwas\"], max_tasks=MAX_TASKS)\n",
    "        \n",
    "        if len(tasks) == 0:\n",
    "            n_skipped += 1\n",
    "            continue\n",
    "        \n",
    "        # Build the prompt\n",
    "        task_prompt = TASK_RATING_PROMPT.format(\n",
    "            mcp_desc=meta[\"text_for_llm\"],\n",
    "            tasks_with_occupations=format_task_list(tasks)\n",
    "        )\n",
    "        \n",
    "        batch_line = {\n",
    "            \"custom_id\": task_custom_id,\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": MODEL,\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": task_prompt}],\n",
    "                \"temperature\": TEMPERATURE,\n",
    "                \"max_tokens\": 4096,\n",
    "            }\n",
    "        }\n",
    "        f.write(json.dumps(batch_line) + \"\\n\")\n",
    "        \n",
    "        task_batch_meta[task_custom_id] = {\n",
    "            \"dwa_custom_id\": dwa_custom_id,\n",
    "            \"tasks\": tasks,\n",
    "            \"used_dwas\": used_dwas,\n",
    "            \"n_tasks_sent\": len(tasks),\n",
    "        }\n",
    "\n",
    "# Save task_batch_meta too so final parse cell survives restart\n",
    "TASK_BATCH_META_PATH = BATCH_DIR / f\"task_batch_meta_{date_str}.pkl\"\n",
    "with open(TASK_BATCH_META_PATH, \"wb\") as f:\n",
    "    pickle.dump(task_batch_meta, f)\n",
    "\n",
    "print(f\"Task rating JSONL written: {TASK_JSONL_PATH}\")\n",
    "print(f\"Requests: {len(task_batch_meta)} (skipped {n_skipped} MCPs with no selected DWAs/tasks)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ko3fgpsl3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file: file-SP6AvxLpCjv7pW6c6rSDWZ\n",
      "Batch created: batch_69960b27279c819080efabb0a983631a\n",
      "Status: validating\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Upload JSONL + create task rating batch\n",
    "# ============================================================\n",
    "\n",
    "task_batch_file = client.files.create(\n",
    "    file=open(TASK_JSONL_PATH, \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "print(f\"Uploaded file: {task_batch_file.id}\")\n",
    "\n",
    "task_batch = client.batches.create(\n",
    "    input_file_id=task_batch_file.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\"description\": f\"Task rating for {len(task_batch_meta)} MCPs\"}\n",
    ")\n",
    "print(f\"Batch created: {task_batch.id}\")\n",
    "print(f\"Status: {task_batch.status}\")\n",
    "\n",
    "TASK_BATCH_ID = task_batch.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zpy1xpa0hhn",
   "metadata": {},
   "source": [
    "## Batch 2: Poll Status + Retrieve Task Results + Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "wo1b2gi4m8i",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:55:37] Status: validating | 0/0 completed, 0 failed\n",
      "[11:56:07] Status: in_progress | 0/1182 completed, 0 failed\n",
      "[11:56:38] Status: in_progress | 0/1182 completed, 0 failed\n",
      "[11:57:08] Status: in_progress | 64/1182 completed, 0 failed\n",
      "[11:57:38] Status: in_progress | 88/1182 completed, 0 failed\n",
      "[11:58:08] Status: in_progress | 115/1182 completed, 0 failed\n",
      "[11:58:38] Status: in_progress | 189/1182 completed, 0 failed\n",
      "[11:59:08] Status: in_progress | 553/1182 completed, 0 failed\n",
      "[11:59:39] Status: in_progress | 882/1182 completed, 0 failed\n",
      "[12:00:09] Status: finalizing | 1182/1182 completed, 0 failed\n",
      "[12:00:39] Status: finalizing | 1182/1182 completed, 0 failed\n",
      "[12:01:09] Status: finalizing | 1182/1182 completed, 0 failed\n",
      "[12:01:39] Status: finalizing | 1182/1182 completed, 0 failed\n",
      "[12:02:10] Status: completed | 1182/1182 completed, 0 failed\n",
      "\n",
      "Task batch complete! Downloaded 1182 results.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Poll task rating batch until complete (auto-waits, checks every 30s)\n",
    "# If you restarted the kernel, set TASK_BATCH_ID manually first:\n",
    "#   TASK_BATCH_ID = \"batch_...\"\n",
    "# ============================================================\n",
    "\n",
    "while True:\n",
    "    task_batch_status = client.batches.retrieve(TASK_BATCH_ID)\n",
    "    status = task_batch_status.status\n",
    "    counts = task_batch_status.request_counts\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] Status: {status} | \"\n",
    "          f\"{counts.completed}/{counts.total} completed, {counts.failed} failed\")\n",
    "    \n",
    "    if status == \"completed\":\n",
    "        task_output_content = client.files.content(task_batch_status.output_file_id).text\n",
    "        task_output_lines = [json.loads(line) for line in task_output_content.strip().split(\"\\n\")]\n",
    "        print(f\"\\nTask batch complete! Downloaded {len(task_output_lines)} results.\")\n",
    "        \n",
    "        if task_batch_status.error_file_id:\n",
    "            task_error_content = client.files.content(task_batch_status.error_file_id).text\n",
    "            print(f\"Error file:\\n{task_error_content[:2000]}\")\n",
    "        break\n",
    "    \n",
    "    elif status in (\"failed\", \"expired\", \"cancelled\"):\n",
    "        print(f\"\\nBatch {status}!\")\n",
    "        if task_batch_status.errors:\n",
    "            for err in task_batch_status.errors.data:\n",
    "                print(f\"  {err.code}: {err.message}\")\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        time.sleep(POLL_INTERVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "y9q03yqt5o",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful task responses: 1182/1182\n",
      "Historical results: 8957 MCPs\n",
      "\n",
      "============================================================\n",
      "Batch classification complete.\n",
      "  New MCPs processed this batch: 1183\n",
      "  Total MCPs in output:          10140\n",
      "Results saved to: mcp_results_2026-02-18.csv\n",
      "\n",
      "Breakdown (new MCPs only):\n",
      "  DWAs selected:    1182\n",
      "  None:             0\n",
      "  Not enough info:  1\n",
      "  Not occ relevant: 0\n",
      "  Total tasks rated:140563\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Parse task rating results + combine with DWA results + merge\n",
    "# with historical results + save final output.\n",
    "# Reloads intermediate state from disk if kernel was restarted.\n",
    "# ============================================================\n",
    "import pickle\n",
    "\n",
    "BATCH_META_PATH      = BATCH_DIR / f\"batch_mcp_meta_{date_str}.pkl\"\n",
    "TASK_BATCH_META_PATH = BATCH_DIR / f\"task_batch_meta_{date_str}.pkl\"\n",
    "\n",
    "# Reload if needed (kernel restart)\n",
    "if \"batch_mcp_meta\" not in dir() or not batch_mcp_meta:\n",
    "    with open(BATCH_META_PATH, \"rb\") as f:\n",
    "        batch_mcp_meta = pickle.load(f)\n",
    "    print(f\"Reloaded batch_mcp_meta from disk ({len(batch_mcp_meta)} MCPs)\")\n",
    "\n",
    "if \"task_batch_meta\" not in dir() or not task_batch_meta:\n",
    "    with open(TASK_BATCH_META_PATH, \"rb\") as f:\n",
    "        task_batch_meta = pickle.load(f)\n",
    "    print(f\"Reloaded task_batch_meta from disk ({len(task_batch_meta)} MCPs)\")\n",
    "\n",
    "# Map custom_id -> response text for task ratings\n",
    "task_responses = {}\n",
    "for line in task_output_lines:\n",
    "    custom_id = line[\"custom_id\"]\n",
    "    if line.get(\"error\"):\n",
    "        print(f\"  Error for {custom_id}: {line['error']}\")\n",
    "        continue\n",
    "    response_body = line[\"response\"][\"body\"]\n",
    "    task_responses[custom_id] = response_body[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "print(f\"Successful task responses: {len(task_responses)}/{len(task_output_lines)}\")\n",
    "\n",
    "# ---- Build results from this batch ----\n",
    "batch_results = []\n",
    "\n",
    "for dwa_custom_id, meta in batch_mcp_meta.items():\n",
    "    mcp_idx = meta[\"mcp_idx\"]\n",
    "    task_custom_id = f\"task-{mcp_idx}\"\n",
    "\n",
    "    result = {\n",
    "        \"title\": meta[\"title\"],\n",
    "        \"url\": meta[\"url\"],\n",
    "        \"text_for_llm\": meta[\"text_for_llm\"],\n",
    "        \"uploaded_clean\": meta[\"uploaded_clean\"],\n",
    "        \"dwa_status\": meta[\"dwa_status\"],\n",
    "        \"dwas_selected\": \"; \".join([d[0] for d in meta[\"selected_dwas\"]]) if meta[\"selected_dwas\"] else \"\",\n",
    "        \"n_dwas_selected\": len(meta[\"selected_dwas\"]),\n",
    "        \"dwa_response_raw\": meta[\"dwa_response_raw\"],\n",
    "        \"task_ratings\": \"\",\n",
    "        \"task_rating_response_raw\": \"\",\n",
    "        \"n_tasks_rated\": 0,\n",
    "    }\n",
    "\n",
    "    if task_custom_id in task_batch_meta and task_custom_id in task_responses:\n",
    "        tmeta = task_batch_meta[task_custom_id]\n",
    "        task_response_raw = task_responses[task_custom_id]\n",
    "        rated_tasks = parse_task_ratings(task_response_raw, tmeta[\"tasks\"])\n",
    "\n",
    "        task_ratings_str = \"; \".join(\n",
    "            [f\"{t} ({o}): {r}\" for t, o, d, r in rated_tasks]\n",
    "        )\n",
    "        result[\"task_ratings\"] = task_ratings_str\n",
    "        result[\"task_rating_response_raw\"] = task_response_raw\n",
    "        result[\"n_tasks_rated\"] = len(rated_tasks)\n",
    "        result[\"n_tasks_sent\"] = tmeta[\"n_tasks_sent\"]\n",
    "        result[\"dwas_used_for_tasks\"] = \"; \".join(tmeta[\"used_dwas\"])\n",
    "\n",
    "    batch_results.append(result)\n",
    "\n",
    "# ---- Combine: partial resume rows + new batch rows ----\n",
    "batch_results_df = pd.DataFrame(batch_results)\n",
    "if not existing_batch_df.empty:\n",
    "    combined_new = pd.concat([existing_batch_df, batch_results_df], ignore_index=True)\n",
    "else:\n",
    "    combined_new = batch_results_df\n",
    "\n",
    "# ---- Merge with historical results from prior runs ----\n",
    "if EXISTING_RESULTS_FILE != \"none\":\n",
    "    historical_df = pd.read_csv(RESULTS_DIR / EXISTING_RESULTS_FILE)\n",
    "    print(f\"Historical results: {len(historical_df)} MCPs\")\n",
    "    save_batch_df = pd.concat([historical_df, combined_new], ignore_index=True)\n",
    "else:\n",
    "    save_batch_df = combined_new\n",
    "\n",
    "save_batch_df.to_csv(BATCH_OUTPUT_PATH, index=False)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Batch classification complete.\")\n",
    "print(f\"  New MCPs processed this batch: {len(batch_results)}\")\n",
    "print(f\"  Total MCPs in output:          {len(save_batch_df)}\")\n",
    "print(f\"Results saved to: {BATCH_OUTPUT_PATH.name}\")\n",
    "print(f\"\\nBreakdown (new MCPs only):\")\n",
    "print(f\"  DWAs selected:    {sum(1 for r in batch_results if r['dwa_status'] == 'selected')}\")\n",
    "print(f\"  None:             {sum(1 for r in batch_results if r['dwa_status'] == 'none')}\")\n",
    "print(f\"  Not enough info:  {sum(1 for r in batch_results if r['dwa_status'] == 'not_enough_info')}\")\n",
    "print(f\"  Not occ relevant: {sum(1 for r in batch_results if r['dwa_status'] == 'not_occ_relevant')}\")\n",
    "print(f\"  Total tasks rated:{sum(r['n_tasks_rated'] for r in batch_results)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wazyzync0l",
   "metadata": {},
   "source": [
    "## Batch Task-Level Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5jcbh37dbwn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10140 MCPs from mcp_results_2026-02-18.csv\n",
      "Total task-rating pairs: 1,205,077\n",
      "Unique (task, occupation) pairs: 11,567\n",
      "\n",
      "Task aggregation saved: task_results_2026-02-18.csv  (11,567 rows)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "task",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "occupation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n_ratings",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mean_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "median_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "max_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "min_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "p25_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p75_rating",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "0aee9048-ea6c-4215-bddf-23bbb8fcb8a8",
       "rows": [
        [
         "0",
         "Document, design, code, or test Geographic Information Systems (GIS) models, internet mapping solutions, or other applications.",
         "Geographic Information Systems Technologists and Technicians",
         "4776",
         "2.22",
         "2.0",
         "5",
         "1",
         "2.0",
         "3.0"
        ],
        [
         "1",
         "Plan, install, repair, or troubleshoot telehealth technology applications or systems in homes.",
         "Health Informatics Specialists",
         "4350",
         "1.36",
         "1.0",
         "3",
         "1",
         "1.0",
         "2.0"
        ],
        [
         "2",
         "Develop and document database architectures.",
         "Database Architects",
         "4301",
         "2.3",
         "2.0",
         "5",
         "1",
         "2.0",
         "3.0"
        ],
        [
         "3",
         "Provide training or technical assistance in Web site implementation or use.",
         "Web Administrators",
         "4103",
         "1.58",
         "2.0",
         "4",
         "1",
         "1.0",
         "2.0"
        ],
        [
         "4",
         "Provide technical support for existing reports, dashboards, or other tools.",
         "Business Intelligence Analysts",
         "4082",
         "1.92",
         "2.0",
         "4",
         "1",
         "1.0",
         "2.0"
        ],
        [
         "5",
         "Provide technical guidance or support for the development or troubleshooting of systems.",
         "Computer Systems Engineers/Architects",
         "4082",
         "1.82",
         "2.0",
         "4",
         "1",
         "1.0",
         "2.0"
        ],
        [
         "6",
         "Inform Web site users of problems, problem resolutions, or application changes and updates.",
         "Web Administrators",
         "4082",
         "1.79",
         "2.0",
         "4",
         "1",
         "1.0",
         "2.0"
        ],
        [
         "7",
         "Provide staff and users with assistance solving computer-related problems, such as malfunctions and program problems.",
         "Computer Systems Analysts",
         "4082",
         "1.73",
         "2.0",
         "4",
         "1",
         "1.0",
         "2.0"
        ],
        [
         "8",
         "Answer user inquiries regarding computer software or hardware operation to resolve problems.",
         "Computer User Support Specialists",
         "4082",
         "1.72",
         "2.0",
         "4",
         "1",
         "1.0",
         "2.0"
        ],
        [
         "9",
         "Provide technical support to junior staff or clients.",
         "Database Administrators",
         "4082",
         "1.7",
         "2.0",
         "4",
         "1",
         "1.0",
         "2.0"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>occupation</th>\n",
       "      <th>n_ratings</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>median_rating</th>\n",
       "      <th>max_rating</th>\n",
       "      <th>min_rating</th>\n",
       "      <th>p25_rating</th>\n",
       "      <th>p75_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Document, design, code, or test Geographic Inf...</td>\n",
       "      <td>Geographic Information Systems Technologists a...</td>\n",
       "      <td>4776</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plan, install, repair, or troubleshoot telehea...</td>\n",
       "      <td>Health Informatics Specialists</td>\n",
       "      <td>4350</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Develop and document database architectures.</td>\n",
       "      <td>Database Architects</td>\n",
       "      <td>4301</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Provide training or technical assistance in We...</td>\n",
       "      <td>Web Administrators</td>\n",
       "      <td>4103</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Provide technical support for existing reports...</td>\n",
       "      <td>Business Intelligence Analysts</td>\n",
       "      <td>4082</td>\n",
       "      <td>1.92</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Provide technical guidance or support for the ...</td>\n",
       "      <td>Computer Systems Engineers/Architects</td>\n",
       "      <td>4082</td>\n",
       "      <td>1.82</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Inform Web site users of problems, problem res...</td>\n",
       "      <td>Web Administrators</td>\n",
       "      <td>4082</td>\n",
       "      <td>1.79</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Provide staff and users with assistance solvin...</td>\n",
       "      <td>Computer Systems Analysts</td>\n",
       "      <td>4082</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Answer user inquiries regarding computer softw...</td>\n",
       "      <td>Computer User Support Specialists</td>\n",
       "      <td>4082</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Provide technical support to junior staff or c...</td>\n",
       "      <td>Database Administrators</td>\n",
       "      <td>4082</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                task  \\\n",
       "0  Document, design, code, or test Geographic Inf...   \n",
       "1  Plan, install, repair, or troubleshoot telehea...   \n",
       "2       Develop and document database architectures.   \n",
       "3  Provide training or technical assistance in We...   \n",
       "4  Provide technical support for existing reports...   \n",
       "5  Provide technical guidance or support for the ...   \n",
       "6  Inform Web site users of problems, problem res...   \n",
       "7  Provide staff and users with assistance solvin...   \n",
       "8  Answer user inquiries regarding computer softw...   \n",
       "9  Provide technical support to junior staff or c...   \n",
       "\n",
       "                                          occupation  n_ratings  mean_rating  \\\n",
       "0  Geographic Information Systems Technologists a...       4776         2.22   \n",
       "1                     Health Informatics Specialists       4350         1.36   \n",
       "2                                Database Architects       4301         2.30   \n",
       "3                                 Web Administrators       4103         1.58   \n",
       "4                     Business Intelligence Analysts       4082         1.92   \n",
       "5              Computer Systems Engineers/Architects       4082         1.82   \n",
       "6                                 Web Administrators       4082         1.79   \n",
       "7                          Computer Systems Analysts       4082         1.73   \n",
       "8                  Computer User Support Specialists       4082         1.72   \n",
       "9                            Database Administrators       4082         1.70   \n",
       "\n",
       "   median_rating  max_rating  min_rating  p25_rating  p75_rating  \n",
       "0            2.0           5           1         2.0         3.0  \n",
       "1            1.0           3           1         1.0         2.0  \n",
       "2            2.0           5           1         2.0         3.0  \n",
       "3            2.0           4           1         1.0         2.0  \n",
       "4            2.0           4           1         1.0         2.0  \n",
       "5            2.0           4           1         1.0         2.0  \n",
       "6            2.0           4           1         1.0         2.0  \n",
       "7            2.0           4           1         1.0         2.0  \n",
       "8            2.0           4           1         1.0         2.0  \n",
       "9            2.0           4           1         1.0         2.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Task-level aggregation for batch results\n",
    "# Loads the combined (historical + new) results file.\n",
    "# ============================================================\n",
    "\n",
    "batch_full_df = pd.read_csv(BATCH_OUTPUT_PATH)\n",
    "print(f\"Loaded {len(batch_full_df)} MCPs from {BATCH_OUTPUT_PATH.name}\")\n",
    "\n",
    "all_batch_task_ratings = []\n",
    "\n",
    "for _, row in batch_full_df.iterrows():\n",
    "    ratings_str = row.get(\"task_ratings\", \"\")\n",
    "    if not isinstance(ratings_str, str) or not ratings_str.strip():\n",
    "        continue\n",
    "\n",
    "    mcp_title = row[\"title\"]\n",
    "    mcp_url = row[\"url\"]\n",
    "\n",
    "    for entry in ratings_str.split(\"; \"):\n",
    "        entry = entry.strip()\n",
    "        if not entry:\n",
    "            continue\n",
    "        match = re.match(r\"^(.+):\\s*(\\d)$\", entry)\n",
    "        if not match:\n",
    "            continue\n",
    "        task_occ_str = match.group(1).strip()\n",
    "        rating = int(match.group(2))\n",
    "\n",
    "        occ_match = re.match(r\"^(.+)\\s*\\(([^)]+)\\)$\", task_occ_str)\n",
    "        if occ_match:\n",
    "            task_text = occ_match.group(1).strip()\n",
    "            occupation = occ_match.group(2).strip()\n",
    "        else:\n",
    "            task_text = task_occ_str\n",
    "            occupation = \"\"\n",
    "\n",
    "        all_batch_task_ratings.append({\n",
    "            \"task\": task_text,\n",
    "            \"occupation\": occupation,\n",
    "            \"rating\": rating,\n",
    "            \"mcp_title\": mcp_title,\n",
    "            \"mcp_url\": mcp_url,\n",
    "        })\n",
    "\n",
    "batch_task_flat = pd.DataFrame(all_batch_task_ratings)\n",
    "print(f\"Total task-rating pairs: {len(batch_task_flat):,}\")\n",
    "print(f\"Unique (task, occupation) pairs: {batch_task_flat.groupby(['task', 'occupation']).ngroups:,}\")\n",
    "\n",
    "batch_task_agg = batch_task_flat.groupby([\"task\", \"occupation\"]).agg(\n",
    "    n_ratings=(\"rating\", \"count\"),\n",
    "    mean_rating=(\"rating\", \"mean\"),\n",
    "    median_rating=(\"rating\", \"median\"),\n",
    "    max_rating=(\"rating\", \"max\"),\n",
    "    min_rating=(\"rating\", \"min\"),\n",
    "    p25_rating=(\"rating\", lambda x: np.percentile(x, 25)),\n",
    "    p75_rating=(\"rating\", lambda x: np.percentile(x, 75)),\n",
    ").reset_index()\n",
    "\n",
    "for col in [\"mean_rating\", \"median_rating\", \"p25_rating\", \"p75_rating\"]:\n",
    "    batch_task_agg[col] = batch_task_agg[col].round(2)\n",
    "\n",
    "batch_task_agg = batch_task_agg.sort_values(\n",
    "    [\"n_ratings\", \"mean_rating\"], ascending=[False, False]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "BATCH_TASK_AGG_PATH = RESULTS_DIR / f\"task_results_{date_str}.csv\"\n",
    "batch_task_agg.to_csv(BATCH_TASK_AGG_PATH, index=False)\n",
    "\n",
    "print(f\"\\nTask aggregation saved: {BATCH_TASK_AGG_PATH.name}  ({len(batch_task_agg):,} rows)\")\n",
    "batch_task_agg.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qh4syk0hvnj",
   "metadata": {},
   "source": [
    "## Batch Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43belrfhk7i",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Utility: List recent batches or cancel a batch\n",
    "# ============================================================\n",
    "\n",
    "# List recent batches\n",
    "print(\"Recent batches:\")\n",
    "for batch in client.batches.list(limit=10):\n",
    "    print(f\"  {batch.id} | {batch.status} | {batch.request_counts.completed}/{batch.request_counts.total} done | {batch.metadata}\")\n",
    "\n",
    "# To cancel a batch, uncomment:\n",
    "# client.batches.cancel(\"batch_...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
