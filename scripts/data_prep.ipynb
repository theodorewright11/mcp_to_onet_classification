{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e098be0",
   "metadata": {},
   "source": [
    "# Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "effa8dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import voyageai\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3334bc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique titles: 8358\n",
      "Titles with duplicates: 951\n",
      "Total duplicate rows: 1759\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_duplicates",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "a14c620f-ab17-472d-abbb-147af4caeb53",
       "rows": [
        [
         "0",
         "MCP Server",
         "51",
         "50"
        ],
        [
         "1",
         "MCP",
         "50",
         "49"
        ],
        [
         "2",
         "GitHub MCP Server",
         "28",
         "27"
        ],
        [
         "3",
         "MCP Servers",
         "23",
         "22"
        ],
        [
         "4",
         "mcp-server",
         "21",
         "20"
        ],
        [
         "5",
         "Weather MCP Server",
         "21",
         "20"
        ],
        [
         "6",
         "mcp",
         "19",
         "18"
        ],
        [
         "7",
         "Linear MCP Server",
         "18",
         "17"
        ],
        [
         "8",
         "mcp-servers",
         "17",
         "16"
        ],
        [
         "9",
         "Jira MCP Server",
         "15",
         "14"
        ],
        [
         "10",
         "Notion MCP Server",
         "15",
         "14"
        ],
        [
         "11",
         "MySQL MCP Server",
         "13",
         "12"
        ],
        [
         "12",
         "Awesome MCP Servers",
         "12",
         "11"
        ],
        [
         "13",
         "Figma MCP Server",
         "12",
         "11"
        ],
        [
         "14",
         "OpenAPI MCP Server",
         "11",
         "10"
        ],
        [
         "15",
         "Kubernetes MCP Server",
         "11",
         "10"
        ],
        [
         "16",
         "Google Calendar MCP Server",
         "10",
         "9"
        ],
        [
         "17",
         "MCP Weather Server",
         "10",
         "9"
        ],
        [
         "18",
         "YouTube MCP Server",
         "10",
         "9"
        ],
        [
         "19",
         "MCP Server Demo",
         "10",
         "9"
        ],
        [
         "20",
         "Mcp Server",
         "10",
         "9"
        ],
        [
         "21",
         "Perplexity MCP Server",
         "9",
         "8"
        ],
        [
         "22",
         "Remote MCP Server on Cloudflare",
         "9",
         "8"
        ],
        [
         "23",
         "Supabase MCP Server",
         "9",
         "8"
        ],
        [
         "24",
         "WhatsApp MCP Server",
         "9",
         "8"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 25
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>count</th>\n",
       "      <th>n_duplicates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MCP Server</td>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MCP</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GitHub MCP Server</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MCP Servers</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mcp-server</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Weather MCP Server</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mcp</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Linear MCP Server</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mcp-servers</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jira MCP Server</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Notion MCP Server</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MySQL MCP Server</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Awesome MCP Servers</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Figma MCP Server</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>OpenAPI MCP Server</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kubernetes MCP Server</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Google Calendar MCP Server</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MCP Weather Server</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>YouTube MCP Server</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MCP Server Demo</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mcp Server</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Perplexity MCP Server</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Remote MCP Server on Cloudflare</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Supabase MCP Server</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>WhatsApp MCP Server</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title  count  n_duplicates\n",
       "0                        MCP Server     51            50\n",
       "1                               MCP     50            49\n",
       "2                 GitHub MCP Server     28            27\n",
       "3                       MCP Servers     23            22\n",
       "4                        mcp-server     21            20\n",
       "5                Weather MCP Server     21            20\n",
       "6                               mcp     19            18\n",
       "7                 Linear MCP Server     18            17\n",
       "8                       mcp-servers     17            16\n",
       "9                   Jira MCP Server     15            14\n",
       "10                Notion MCP Server     15            14\n",
       "11                 MySQL MCP Server     13            12\n",
       "12              Awesome MCP Servers     12            11\n",
       "13                 Figma MCP Server     12            11\n",
       "14               OpenAPI MCP Server     11            10\n",
       "15            Kubernetes MCP Server     11            10\n",
       "16       Google Calendar MCP Server     10             9\n",
       "17               MCP Weather Server     10             9\n",
       "18               YouTube MCP Server     10             9\n",
       "19                  MCP Server Demo     10             9\n",
       "20                       Mcp Server     10             9\n",
       "21            Perplexity MCP Server      9             8\n",
       "22  Remote MCP Server on Cloudflare      9             8\n",
       "23              Supabase MCP Server      9             8\n",
       "24              WhatsApp MCP Server      9             8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load file\n",
    "df = pd.read_csv(\"../data/mcp/results/mcp_results_2026-02-18.csv\")\n",
    "\n",
    "# Count titles properly\n",
    "title_counts = (\n",
    "    df.groupby(\"title\")\n",
    "      .size()\n",
    "      .reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "# Ensure numeric\n",
    "title_counts[\"count\"] = pd.to_numeric(title_counts[\"count\"], errors=\"coerce\")\n",
    "\n",
    "# Only duplicates\n",
    "duplicates_only = (\n",
    "    title_counts[title_counts[\"count\"] > 1]\n",
    "    .sort_values(\"count\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "duplicates_only[\"n_duplicates\"] = duplicates_only[\"count\"] - 1\n",
    "\n",
    "print(f\"Total unique titles: {df['title'].nunique()}\")\n",
    "print(f\"Titles with duplicates: {len(duplicates_only)}\")\n",
    "print(f\"Total duplicate rows: {duplicates_only['n_duplicates'].sum()}\")\n",
    "\n",
    "duplicates_only.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "va32c0y90cj",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaii061tjf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: mcp_scraped_2026-02-18.csv  (date_str = 2026-02-18)\n",
      "Output MCP data file  : data/mcp/raw/mcp_data_2026-02-18.csv\n",
      "Output MCP embeddings : data/embeddings/voyage_mcp_emb_2026-02-18.npy\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Config — set this before running\n",
    "# ============================================================\n",
    "# Name of the raw scrape file to process (produced by mcp_scraper.py).\n",
    "# Set to None to auto-detect the most recent mcp_scraped_*.csv in data/mcp/raw/.\n",
    "RAW_SCRAPE_FILE = \"mcp_scraped_2026-02-18.csv\"  # e.g. \"mcp_scraped_2026-02-17.csv\"\n",
    "\n",
    "# ---- Auto-detect if not specified ----\n",
    "DATA_DIR = Path(\"../data\")\n",
    "RAW_DIR = DATA_DIR / \"mcp\" / \"raw\"\n",
    "if RAW_SCRAPE_FILE is None:\n",
    "    scrape_files = sorted(RAW_DIR.glob(\"mcp_scraped_*.csv\"))\n",
    "    if not scrape_files:\n",
    "        raise FileNotFoundError(\"No mcp_scraped_*.csv files found in data/mcp/raw/\")\n",
    "    RAW_SCRAPE_FILE = scrape_files[-1].name\n",
    "    print(f\"Auto-detected scrape file: {RAW_SCRAPE_FILE}\")\n",
    "\n",
    "# Extract date from filename so all outputs share the same date stamp\n",
    "date_str = RAW_SCRAPE_FILE.replace(\"mcp_scraped_\", \"\").replace(\".csv\", \"\")\n",
    "print(f\"Processing: {RAW_SCRAPE_FILE}  (date_str = {date_str})\")\n",
    "print(f\"Output MCP data file  : data/mcp/raw/mcp_data_{date_str}.csv\")\n",
    "print(f\"Output MCP embeddings : data/embeddings/voyage_mcp_emb_{date_str}.npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8680293",
   "metadata": {},
   "source": [
    "# Data Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e9f389",
   "metadata": {},
   "source": [
    "## O*NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb91eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Load the two datasets ----------\n",
    "tasks = pd.read_csv(\"../data/onet/tasks_to_dwas_v30.1.csv\")  \n",
    "dwa_ref = pd.read_csv(\"../data/onet/dwa_reference_v30.1.csv\")       \n",
    "\n",
    "\n",
    "# ---------- Merge on DWA ID ----------\n",
    "merged = tasks.merge(\n",
    "    dwa_ref[[\"DWA ID\", \"IWA ID\", \"IWA Title\", \"Element ID\", \"Element Name\"]],\n",
    "    on=\"DWA ID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# ---------- Rename standardized columns ----------\n",
    "merged = merged.rename(columns={\n",
    "    \"Task ID\": \"task_id\",\n",
    "    \"Task\": \"task\",\n",
    "    \"DWA ID\": \"dwa_id\",\n",
    "    \"DWA Title\": \"dwa_title\",\n",
    "    \"IWA ID\": \"iwa_id\",\n",
    "    \"IWA Title\": \"iwa_title\",\n",
    "    \"Element ID\": \"gwa_id\",\n",
    "    \"Element Name\": \"gwa_title\",\n",
    "    \"O*NET-SOC Code\": \"soc_code\",\n",
    "    \"Title\": \"title\"   \n",
    "})\n",
    "\n",
    "# ---------- Select relevant columns ----------\n",
    "cols_to_keep = [\n",
    "    \"task_id\", \"task\",\n",
    "    \"dwa_id\", \"dwa_title\",\n",
    "    \"iwa_id\", \"iwa_title\",\n",
    "    \"gwa_id\", \"gwa_title\",\n",
    "    \"soc_code\", \"title\"\n",
    "]\n",
    "merged = merged[[c for c in cols_to_keep if c in merged.columns]]\n",
    "\n",
    "# Optional save full hierarchy for reference\n",
    "# merged.to_csv(\"../data/onet_full_hierarchy.csv\", index=False)\n",
    "\n",
    "# Keep only the columns relevant for the cascading sheet\n",
    "merged = merged[[\n",
    "    \"dwa_title\", \"task\", \"title\"\n",
    "]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Save \n",
    "merged.to_csv(\"../data/onet/onet_data.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d75a887",
   "metadata": {},
   "source": [
    "## MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed520867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 duplicate rows\n",
      "Cleaned dataset saved: data/mcp/raw/mcp_data_2026-02-18.csv  (1183 rows)\n"
     ]
    }
   ],
   "source": [
    "# Load raw data\n",
    "df = pd.read_csv(RAW_DIR / RAW_SCRAPE_FILE)\n",
    "\n",
    "# --- 1. Remove emojis / non-ascii ---\n",
    "def remove_non_ascii(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    return text\n",
    "\n",
    "for col in [\"title\", \"description\", \"use_cases\", \"key_features\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(remove_non_ascii).str.strip()\n",
    "\n",
    "\n",
    "# --- 2. Drop junk / empty text ---\n",
    "def is_useless_desc(text):\n",
    "    if not isinstance(text, str):\n",
    "        return True\n",
    "    txt = text.lower().strip()\n",
    "    if len(txt.split()) < 5:\n",
    "        return True\n",
    "    bad_patterns = [\"mirror\", \"demo\", \"test\"]\n",
    "    return any(p in txt for p in bad_patterns)\n",
    "\n",
    "df[\"desc_is_useless\"] = df[\"description\"].apply(is_useless_desc)\n",
    "df[\"has_use_cases\"] = df[\"use_cases\"].notna() & (df[\"use_cases\"].str.strip() != \"\")\n",
    "\n",
    "# keep if we have use cases OR meaningful description\n",
    "df = df[(~df[\"desc_is_useless\"]) | (df[\"has_use_cases\"])].reset_index(drop=True)\n",
    "\n",
    "# --- 3. Clean whitespace, collapse doubles ---\n",
    "df = df.replace({r'\\s+': ' '}, regex=True)\n",
    "\n",
    "# --- 4. Standardize uploaded column (YYYY-MM-DD format) ---\n",
    "def parse_relative_date(text):\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "\n",
    "    m = re.search(r\"(\\d+)\\s*(year|month|week|day)s?\\s*ago\", text.lower())\n",
    "    if not m:\n",
    "        return None\n",
    "\n",
    "    num, unit = int(m.group(1)), m.group(2)\n",
    "    now = datetime.now()\n",
    "\n",
    "    if unit == \"year\":\n",
    "        dt = now - timedelta(days=num * 365)\n",
    "    elif unit == \"month\":\n",
    "        dt = now - timedelta(days=num * 30)\n",
    "    elif unit == \"week\":\n",
    "        dt = now - timedelta(weeks=num)\n",
    "    elif unit == \"day\":\n",
    "        dt = now - timedelta(days=num)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    return dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "df[\"uploaded_clean\"] = df[\"uploaded\"].apply(parse_relative_date)\n",
    "\n",
    "\n",
    "def combine_text_with_features(desc, use, features):\n",
    "    parts = []\n",
    "    if isinstance(desc, str) and desc.strip():\n",
    "        parts.append(f\"Description: {desc.strip()}\")\n",
    "    if isinstance(features, str) and features.strip():\n",
    "        parts.append(f\"Key features: {features.strip()}\")\n",
    "    if isinstance(use, str) and use.strip():\n",
    "        parts.append(f\"Use cases: {use.strip()}\")\n",
    "    return \"; \".join(parts)\n",
    "\n",
    "df[\"text_for_llm\"] = df.apply(\n",
    "    lambda x: combine_text_with_features(\n",
    "        x[\"description\"], x[\"use_cases\"], x[\"key_features\"]\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# --- 6. Drop rows with no usable text at all ---\n",
    "df = df[df[\"text_for_llm\"].str.strip() != \"\"]\n",
    "\n",
    "# --- Deduplicate on final LLM input ---\n",
    "before = len(df)\n",
    "df = df.drop_duplicates(subset=[\"text_for_llm\"]).reset_index(drop=True)\n",
    "after = len(df)\n",
    "print(f\"Removed {before - after} duplicate rows\")\n",
    "\n",
    "# --- 7. Drop short junk entries ---\n",
    "df[\"len_text\"] = df[\"text_for_llm\"].str.len()\n",
    "df = df[df[\"len_text\"] > 40]\n",
    "\n",
    "# drop helper / raw columns\n",
    "cols_to_drop = [\n",
    "    \"uploaded\", \"use_cases\", \"description\", \"key_features\",\n",
    "    \"desc_is_useless\", \"has_use_cases\", \"len_text\"\n",
    "]\n",
    "df = df.drop(columns=[c for c in cols_to_drop if c in df.columns])\n",
    "\n",
    "# --- 8. Save cleaned dataset ---\n",
    "out_file = f\"mcp_data_{date_str}.csv\"\n",
    "df.to_csv(RAW_DIR / out_file, index=False)\n",
    "print(f\"Cleaned dataset saved: data/mcp/raw/{out_file}  ({len(df)} rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac92d6be",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mkgx2lsui9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Load cleaned MCP data + O*NET for embedding\n",
    "# ============================================================\n",
    "\n",
    "mcp_df = pd.read_csv(RAW_DIR / f\"mcp_data_{date_str}.csv\")\n",
    "onet_df = pd.read_csv(DATA_DIR / \"onet/onet_data.csv\")\n",
    "\n",
    "mcp_texts = mcp_df[\"text_for_llm\"].tolist()\n",
    "mcp_titles = mcp_df[\"title\"].tolist()\n",
    "\n",
    "# Unique DWA titles only (no point embedding duplicates)\n",
    "dwa_titles_unique = onet_df[\"dwa_title\"].dropna().drop_duplicates().reset_index(drop=True).tolist()\n",
    "\n",
    "print(f\"MCP texts to embed:     {len(mcp_texts):,}\")\n",
    "print(f\"Unique DWA titles:      {len(dwa_titles_unique):,}\")\n",
    "print(f\"O*NET rows (total):     {len(onet_df):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ma1p2moait",
   "metadata": {},
   "source": [
    "## Voyage-4-large Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4rwcdoz41gb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Voyage-4-large embeddings\n",
    "# Requires VOYAGE_API_KEY in your .env file\n",
    "# ============================================================\n",
    "\n",
    "VOYAGE_MODEL = \"voyage-4-large\"\n",
    "VOYAGE_BATCH = 128\n",
    "load_dotenv()\n",
    "vo = voyageai.Client()  # reads VOYAGE_API_KEY from env\n",
    "\n",
    "def voyage_embed_batched(texts, input_type=\"document\", batch_size=VOYAGE_BATCH):\n",
    "    \"\"\"Embed texts in batches via Voyage API.\"\"\"\n",
    "    all_embs = []\n",
    "    total_batches = (len(texts) - 1) // batch_size + 1\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_num = i // batch_size + 1\n",
    "        batch = texts[i : i + batch_size]\n",
    "        result = vo.embed(batch, model=VOYAGE_MODEL, input_type=input_type)\n",
    "        all_embs.extend(result.embeddings)\n",
    "        print(f\"  Batch {batch_num}/{total_batches} complete\")\n",
    "    return np.array(all_embs, dtype=np.float32)\n",
    "\n",
    "emb_dir = DATA_DIR / \"embeddings\"\n",
    "emb_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# ---------- MCP embeddings (generated per scrape batch) ----------\n",
    "print(f\"Embedding {len(mcp_texts):,} MCP texts with {VOYAGE_MODEL}...\")\n",
    "voyage_mcp_emb = voyage_embed_batched(mcp_texts, input_type=\"document\")\n",
    "print(f\"  Shape: {voyage_mcp_emb.shape}\")\n",
    "\n",
    "mcp_emb_path = emb_dir / f\"voyage_mcp_emb_{date_str}.npy\"\n",
    "np.save(mcp_emb_path, voyage_mcp_emb)\n",
    "print(f\"  Saved to: {mcp_emb_path.name}\")\n",
    "\n",
    "# ---------- DWA embeddings (generated once; reused for all future batches) ----------\n",
    "dwa_emb_path = emb_dir / \"voyage_dwa_emb.npy\"\n",
    "if dwa_emb_path.exists():\n",
    "    print(f\"\\nDWA embeddings already exist — loading from disk.\")\n",
    "    voyage_dwa_emb = np.load(dwa_emb_path)\n",
    "    print(f\"  Shape: {voyage_dwa_emb.shape}\")\n",
    "else:\n",
    "    print(f\"\\nGenerating DWA embeddings with {VOYAGE_MODEL}...\")\n",
    "    voyage_dwa_emb = voyage_embed_batched(dwa_titles_unique, input_type=\"document\")\n",
    "    print(f\"  Shape: {voyage_dwa_emb.shape}\")\n",
    "    np.save(dwa_emb_path, voyage_dwa_emb)\n",
    "    print(f\"  Saved to: {dwa_emb_path.name}\")\n",
    "\n",
    "print(f\"\\nEmbeddings ready. Pass these paths to llm_classification.ipynb:\")\n",
    "print(f\"  MCP_DATA_FILE = \\\"mcp_data_{date_str}.csv\\\"\")\n",
    "print(f\"  MCP_EMB_FILE  = \\\"voyage_mcp_emb_{date_str}.npy\\\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
